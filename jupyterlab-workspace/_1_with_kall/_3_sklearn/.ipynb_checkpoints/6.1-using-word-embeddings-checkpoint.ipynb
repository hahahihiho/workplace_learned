{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![word embeddings vs. one hot encoding](https://s3.amazonaws.com/book.keras.io/img/ch6/word_embeddings.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# 특성으로 사용할 단어의 수\n",
    "max_features = 10000\n",
    "# 사용할 텍스트의 길이(가장 빈번한 max_features 개의 단어만 사용합니다)\n",
    "maxlen = 500\n",
    "\n",
    "# 정수 리스트로 데이터를 로드합니다.\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 리스트를 (samples, maxlen) 크기의 2D 정수 텐서로 변환합니다.\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,  194, 1153,  194, 8255,   78,  228,    5,    6, 1463, 4369,\n",
       "       5012,  134,   26,    4,  715,    8,  118, 1634,   14,  394,   20,\n",
       "         13,  119,  954,  189,  102,    5,  207,  110, 3103,   21,   14,\n",
       "         69,  188,    8,   30,   23,    7,    4,  249,  126,   93,    4,\n",
       "        114,    9, 2300, 1523,    5,  647,    4,  116,    9,   35, 8163,\n",
       "          4,  229,    9,  340, 1322,    4,  118,    9,    4,  130, 4901,\n",
       "         19,    4, 1002,    5,   89,   29,  952,   46,   37,    4,  455,\n",
       "          9,   45,   43,   38, 1543, 1905,  398,    4, 1649,   26, 6853,\n",
       "          5,  163,   11, 3215,    2,    4, 1153,    9,  194,  775,    7,\n",
       "       8255,    2,  349, 2637,  148,  605,    2, 8003,   15,  123,  125,\n",
       "         68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,  228,\n",
       "          9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,   11,\n",
       "        220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,  656,\n",
       "        245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,   32,\n",
       "       7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64, 1382,\n",
       "          9,    8,  168,  145,   23,    4, 1690,   15,   16,    4, 1355,\n",
       "          5,   28,    6,   52,  154,  462,   33,   89,   78,  285,   16,\n",
       "        145,   95,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer 및 모델 프레임워크\n",
    "\n",
    "- Embedding 층은 크기가 (samples, sequence_length)인 2D 정수 텐서를 입력으로 받음\n",
    "- output은 (samples, sequence_length, embedding_dimensionality)인 3D 실수형 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4001      \n",
      "=================================================================\n",
      "Total params: 84,001\n",
      "Trainable params: 84,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 나중에 임베딩된 입력을 Flatten 층에서 펼치기 위해 Embedding 층에 input_length를 지정\n",
    "# input_length 지정하지 않으면 (None, None, 8)이 되어 Flatten() 불가능\n",
    "# Embedding 층의 출력 크기는 (samples, maxlen, 8)\n",
    "model.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "\n",
    "# 3D 임베딩 텐서를 (samples, maxlen * 8) 크기의 2D 텐서로 펼칩니다.\n",
    "model.add(Flatten())\n",
    "# 분류기를 추가합니다.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "model1.add(Flatten())\n",
    "\n",
    "# 학습층 추가\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "\n",
    "# 분류기를 추가\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 6s 292us/step - loss: 0.4776 - acc: 0.7507 - val_loss: 0.3109 - val_acc: 0.8722\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 5s 257us/step - loss: 0.2370 - acc: 0.9058 - val_loss: 0.3185 - val_acc: 0.8700\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 5s 252us/step - loss: 0.1568 - acc: 0.9411 - val_loss: 0.3179 - val_acc: 0.8786\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 5s 243us/step - loss: 0.0967 - acc: 0.9659 - val_loss: 0.3985 - val_acc: 0.8644\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 5s 246us/step - loss: 0.0564 - acc: 0.9816 - val_loss: 0.5058 - val_acc: 0.8606\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 5s 248us/step - loss: 0.0284 - acc: 0.9914 - val_loss: 0.6725 - val_acc: 0.8534\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 5s 255us/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.8451 - val_acc: 0.8424\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.0064 - acc: 0.9987 - val_loss: 0.9492 - val_acc: 0.8324\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 5s 243us/step - loss: 0.0032 - acc: 0.9992 - val_loss: 1.1680 - val_acc: 0.8312\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 5s 252us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 1.3724 - val_acc: 0.8168\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 7s 332us/step - loss: 0.4726 - acc: 0.7504 - val_loss: 0.3144 - val_acc: 0.8718\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 5s 269us/step - loss: 0.2250 - acc: 0.9109 - val_loss: 0.3059 - val_acc: 0.8716\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 5s 260us/step - loss: 0.1447 - acc: 0.9457 - val_loss: 0.3263 - val_acc: 0.8750\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 5s 257us/step - loss: 0.0876 - acc: 0.9698 - val_loss: 0.4250 - val_acc: 0.8690\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 5s 254us/step - loss: 0.0484 - acc: 0.9846 - val_loss: 0.4847 - val_acc: 0.8610\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 5s 254us/step - loss: 0.0241 - acc: 0.9929 - val_loss: 0.6471 - val_acc: 0.8598\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 5s 255us/step - loss: 0.0113 - acc: 0.9969 - val_loss: 0.8701 - val_acc: 0.8418\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 5s 257us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.9794 - val_acc: 0.8394\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 5s 256us/step - loss: 0.0023 - acc: 0.9992 - val_loss: 1.1550 - val_acc: 0.8392\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 5s 258us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 1.3537 - val_acc: 0.8364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24bdca82438>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(None,))\n",
    "embedding = Embedding(input_dim = max_features, output_dim=8, input_length=maxlen)(inputs)\n",
    "output1 = Flatten()(embedding)\n",
    "output2 = Dense(32, activation='relu')(output1)\n",
    "predictions = Dense(1, activation='sigmoid')(output2)\n",
    "api_model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "api_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "api_model.fit(x_train, y_train,\n",
    "              epochs=10,\n",
    "              batch_size=32,\n",
    "              validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_12 (Embedding)     (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "api_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 114us/step\n",
      "test_acc: 0.803\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = api_model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규제 방식\n",
    "\n",
    "### 1. hidden node, layer의 수\n",
    "### 2. l2, l1 규제 --> from keras import regularizers\n",
    "### 3. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regularizer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 6s 288us/step - loss: 0.5191 - acc: 0.7495 - val_loss: 0.3693 - val_acc: 0.8688\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 5s 250us/step - loss: 0.3123 - acc: 0.8936 - val_loss: 0.3567 - val_acc: 0.8672\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 5s 255us/step - loss: 0.2557 - acc: 0.9161 - val_loss: 0.3623 - val_acc: 0.8638\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 5s 260us/step - loss: 0.2148 - acc: 0.9353 - val_loss: 0.3456 - val_acc: 0.8808\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 5s 255us/step - loss: 0.1803 - acc: 0.9511 - val_loss: 0.3881 - val_acc: 0.8738\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 5s 240us/step - loss: 0.1463 - acc: 0.9660 - val_loss: 0.3969 - val_acc: 0.8748\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 5s 244us/step - loss: 0.1165 - acc: 0.9780 - val_loss: 0.4277 - val_acc: 0.8720\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 5s 257us/step - loss: 0.0920 - acc: 0.9840 - val_loss: 0.4653 - val_acc: 0.8644\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 5s 255us/step - loss: 0.0744 - acc: 0.9888 - val_loss: 0.4896 - val_acc: 0.8660\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 5s 241us/step - loss: 0.0613 - acc: 0.9917 - val_loss: 0.5460 - val_acc: 0.8554\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "from keras import regularizers\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model2.summary()\n",
    "\n",
    "history2 = model2.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 115us/step\n",
      "test_acc: 0.82824\n"
     ]
    }
   ],
   "source": [
    "test_loss2, test_acc2 = model2.evaluate(x_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout 추가, l2 규제 강화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                64016     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 144,033\n",
      "Trainable params: 144,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 7s 335us/step - loss: 0.7519 - acc: 0.5105 - val_loss: 0.6950 - val_acc: 0.5526\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 6s 278us/step - loss: 0.6250 - acc: 0.7444 - val_loss: 0.5328 - val_acc: 0.8182\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 6s 280us/step - loss: 0.4703 - acc: 0.8565 - val_loss: 0.4510 - val_acc: 0.8628\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 6s 280us/step - loss: 0.4097 - acc: 0.8805 - val_loss: 0.4154 - val_acc: 0.8730\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 5s 268us/step - loss: 0.3736 - acc: 0.8925 - val_loss: 0.4029 - val_acc: 0.8750\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 5s 273us/step - loss: 0.3508 - acc: 0.9015 - val_loss: 0.3938 - val_acc: 0.8824\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 5s 273us/step - loss: 0.3313 - acc: 0.9088 - val_loss: 0.3967 - val_acc: 0.8776\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 5s 266us/step - loss: 0.3179 - acc: 0.9156 - val_loss: 0.3847 - val_acc: 0.8784\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 5s 270us/step - loss: 0.3074 - acc: 0.9170 - val_loss: 0.3818 - val_acc: 0.8830\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 5s 262us/step - loss: 0.2961 - acc: 0.9228 - val_loss: 0.3733 - val_acc: 0.8842\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 6s 283us/step - loss: 0.2872 - acc: 0.9257 - val_loss: 0.3866 - val_acc: 0.8840\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 5s 263us/step - loss: 0.2805 - acc: 0.9292 - val_loss: 0.3813 - val_acc: 0.8826\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 5s 272us/step - loss: 0.2726 - acc: 0.9301 - val_loss: 0.3765 - val_acc: 0.8858\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 5s 263us/step - loss: 0.2679 - acc: 0.9330 - val_loss: 0.3855 - val_acc: 0.8840\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 5s 272us/step - loss: 0.2623 - acc: 0.9347 - val_loss: 0.3823 - val_acc: 0.8822\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 6s 277us/step - loss: 0.2560 - acc: 0.9366 - val_loss: 0.3854 - val_acc: 0.8872\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 5s 272us/step - loss: 0.2480 - acc: 0.9422 - val_loss: 0.3957 - val_acc: 0.8802\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 6s 277us/step - loss: 0.2488 - acc: 0.9412 - val_loss: 0.4076 - val_acc: 0.8770\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 5s 272us/step - loss: 0.2436 - acc: 0.9430 - val_loss: 0.4002 - val_acc: 0.8816\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 5s 262us/step - loss: 0.2398 - acc: 0.9452 - val_loss: 0.4121 - val_acc: 0.8822\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim = max_features, output_dim=8, input_length=maxlen))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model3.summary()\n",
    "\n",
    "history3 = model3.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 132us/step\n",
      "test_acc: 0.86608\n"
     ]
    }
   ],
   "source": [
    "test_loss3, test_acc3 = model3.evaluate(x_test, y_test)\n",
    "\n",
    "print('test_acc:', test_acc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = model3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03778443],\n",
       "       [0.9997555 ],\n",
       "       [0.53632   ],\n",
       "       ...,\n",
       "       [0.01860744],\n",
       "       [0.18853775],\n",
       "       [0.3339418 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "- DNN, CNN은 메모리가 없음\n",
    "- 따라서, 시퀀스가 있는 데이터를 시퀀스를 고려하여 처리하지는 못한다\n",
    "\n",
    "- 순환신경망(Recurrent Neural Network)은 처리한 정보를 상태(state)에 저장함\n",
    "- RNN은 내부에 루프를 가진 신경망의 한 종류\n",
    "- RNN의 상태(state)는 2개의 다른 시퀀스를 처리하는 사이에 재설정 됨\n",
    "\n",
    "![rnn_모식](./image/rnn_outline.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rnn_개념도](./image/rnn_concept.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "rnn_model.add(SimpleRNN(32))\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5711248020499879688\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6622735237\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11962634604598583125\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Embedding, SimpleRNN\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(SimpleRNN(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = model.fit(input_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩...\n",
      "25000 훈련 시퀀스\n",
      "25000 테스트 시퀀스\n",
      "시퀀스 패딩 (samples x time)\n",
      "input_train 크기: (25000, 500)\n",
      "input_test 크기: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 10000  # 특성으로 사용할 단어의 수\n",
    "maxlen = 500  # 사용할 텍스트의 길이(가장 빈번한 max_features 개의 단어만 사용합니다)\n",
    "batch_size = 32\n",
    "\n",
    "print('데이터 로딩...')\n",
    "(input_train, yy_train), (input_test, yy_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(input_train), '훈련 시퀀스')\n",
    "print(len(input_test), '테스트 시퀀스')\n",
    "\n",
    "print('시퀀스 패딩 (samples x time)')\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=maxlen)\n",
    "input_test = sequence.pad_sequences(input_test, maxlen=maxlen)\n",
    "print('input_train 크기:', input_train.shape)\n",
    "print('input_test 크기:', input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.6474 - acc: 0.6087 - val_loss: 0.4873 - val_acc: 0.7892\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.4159 - acc: 0.8226 - val_loss: 0.5721 - val_acc: 0.7444\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 20s 1ms/step - loss: 0.2938 - acc: 0.8847 - val_loss: 0.3602 - val_acc: 0.8476\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.2265 - acc: 0.9143 - val_loss: 0.4139 - val_acc: 0.8218\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.1726 - acc: 0.9361 - val_loss: 0.3704 - val_acc: 0.8594\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 0.1276 - acc: 0.9558 - val_loss: 0.3696 - val_acc: 0.8656\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0851 - acc: 0.9713 - val_loss: 0.4372 - val_acc: 0.8470\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0556 - acc: 0.9829 - val_loss: 0.5175 - val_acc: 0.8290\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0342 - acc: 0.9899 - val_loss: 0.6408 - val_acc: 0.7960\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.0247 - acc: 0.9924 - val_loss: 0.6137 - val_acc: 0.8222\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "    rnn_model.add(SimpleRNN(32))\n",
    "    rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    rnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = rnn_model.fit(input_train, yy_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_4 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 21s 1ms/step - loss: 2.1727 - acc: 0.5483 - val_loss: 1.0420 - val_acc: 0.7196\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.7028 - acc: 0.7343 - val_loss: 0.5086 - val_acc: 0.8120\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.4823 - acc: 0.8244 - val_loss: 0.3991 - val_acc: 0.8520\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.3940 - acc: 0.8620 - val_loss: 0.4867 - val_acc: 0.7884\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 23s 1ms/step - loss: 0.3447 - acc: 0.8795 - val_loss: 0.3675 - val_acc: 0.8676\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.3240 - acc: 0.8910 - val_loss: 0.3566 - val_acc: 0.8684\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.2885 - acc: 0.9040 - val_loss: 0.4205 - val_acc: 0.8564\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.2965 - acc: 0.8978 - val_loss: 0.3568 - val_acc: 0.8752\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.2727 - acc: 0.9077 - val_loss: 0.4061 - val_acc: 0.8630\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 22s 1ms/step - loss: 0.2434 - acc: 0.9211 - val_loss: 0.3905 - val_acc: 0.8498\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Dropout\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "    rnn_model.add(SimpleRNN(32, kernel_regularizer=regularizers.l2(0.1)))\n",
    "    rnn_model.add(Dropout(0.5))\n",
    "    rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    rnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = rnn_model.fit(input_train, yy_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"0000:01:00.0\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "# cpu 지정\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Dropout, SimpleRNN\n",
    "from keras import regularizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " 1312/20000 [>.............................] - ETA: 4:01 - loss: 0.7018 - acc: 0.4840"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=32,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\GIGABYTE\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " 1440/20000 [=>............................] - ETA: 4:58 - loss: 0.6927 - acc: 0.5146"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-aa1f56064fb3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                         validation_split=0.2)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=32,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "rnn_history = rnn_model.fit(x_train, y_train,\n",
    "                            epochs=10,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "![LSTM_개념도](./image/lstm_concept.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 32))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 13s 648us/step - loss: 0.5023 - acc: 0.7511 - val_loss: 0.4716 - val_acc: 0.7694\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 7s 372us/step - loss: 0.3095 - acc: 0.8735 - val_loss: 0.2928 - val_acc: 0.8782\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 8s 375us/step - loss: 0.2524 - acc: 0.9052 - val_loss: 0.2959 - val_acc: 0.8828\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 8s 378us/step - loss: 0.2139 - acc: 0.9172 - val_loss: 0.3314 - val_acc: 0.8560\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 8s 377us/step - loss: 0.1849 - acc: 0.9290 - val_loss: 0.2908 - val_acc: 0.8882\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 8s 379us/step - loss: 0.1694 - acc: 0.9387 - val_loss: 0.3084 - val_acc: 0.8662\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 8s 377us/step - loss: 0.1477 - acc: 0.9484 - val_loss: 0.3214 - val_acc: 0.8886\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 8s 376us/step - loss: 0.1395 - acc: 0.9496 - val_loss: 0.4763 - val_acc: 0.8554\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 8s 378us/step - loss: 0.1303 - acc: 0.9543 - val_loss: 0.3353 - val_acc: 0.8700\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 8s 379us/step - loss: 0.1130 - acc: 0.9607 - val_loss: 0.3824 - val_acc: 0.8876\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 8s 380us/step - loss: 0.1140 - acc: 0.9614 - val_loss: 0.3582 - val_acc: 0.8808\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 8s 386us/step - loss: 0.1013 - acc: 0.9660 - val_loss: 0.3900 - val_acc: 0.8802\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 8s 383us/step - loss: 0.0902 - acc: 0.9683 - val_loss: 0.4011 - val_acc: 0.8782\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 8s 379us/step - loss: 0.0832 - acc: 0.9723 - val_loss: 0.3899 - val_acc: 0.8804\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 8s 380us/step - loss: 0.0769 - acc: 0.9750 - val_loss: 0.4219 - val_acc: 0.8794\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 8s 380us/step - loss: 0.0753 - acc: 0.9746 - val_loss: 0.3969 - val_acc: 0.8728\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 8s 381us/step - loss: 0.0616 - acc: 0.9800 - val_loss: 0.5348 - val_acc: 0.8722\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 8s 379us/step - loss: 0.0671 - acc: 0.9786 - val_loss: 0.4621 - val_acc: 0.8652\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 8s 381us/step - loss: 0.0548 - acc: 0.9828 - val_loss: 0.6023 - val_acc: 0.8228\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 8s 381us/step - loss: 0.0531 - acc: 0.9834 - val_loss: 0.4705 - val_acc: 0.8734\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 9s 461us/step - loss: 2.3630 - acc: 0.6210 - val_loss: 0.9418 - val_acc: 0.5758\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 8s 392us/step - loss: 0.5612 - acc: 0.8121 - val_loss: 0.3924 - val_acc: 0.8560\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 8s 397us/step - loss: 0.3301 - acc: 0.8889 - val_loss: 0.3528 - val_acc: 0.8706\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 8s 397us/step - loss: 0.2854 - acc: 0.9134 - val_loss: 0.3460 - val_acc: 0.8764\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 8s 395us/step - loss: 0.2278 - acc: 0.9317 - val_loss: 0.3198 - val_acc: 0.8816\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 8s 392us/step - loss: 0.2118 - acc: 0.9402 - val_loss: 0.4661 - val_acc: 0.8452\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 8s 393us/step - loss: 0.1790 - acc: 0.9496 - val_loss: 0.3612 - val_acc: 0.8750\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 8s 395us/step - loss: 0.1587 - acc: 0.9568 - val_loss: 0.3456 - val_acc: 0.8702\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 8s 391us/step - loss: 0.1420 - acc: 0.9633 - val_loss: 0.3681 - val_acc: 0.8648\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 8s 394us/step - loss: 0.1544 - acc: 0.9584 - val_loss: 0.4481 - val_acc: 0.8638\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 8s 395us/step - loss: 0.1303 - acc: 0.9669 - val_loss: 0.3860 - val_acc: 0.8576\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 8s 392us/step - loss: 0.1126 - acc: 0.9740 - val_loss: 0.4184 - val_acc: 0.8638\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 8s 394us/step - loss: 0.1165 - acc: 0.9704 - val_loss: 0.4693 - val_acc: 0.8688\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 8s 390us/step - loss: 0.1097 - acc: 0.9740 - val_loss: 0.4672 - val_acc: 0.8682\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 8s 393us/step - loss: 0.1007 - acc: 0.9772 - val_loss: 0.6005 - val_acc: 0.8500\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 8s 396us/step - loss: 0.0948 - acc: 0.9790 - val_loss: 0.4936 - val_acc: 0.8630\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 8s 396us/step - loss: 0.0886 - acc: 0.9806 - val_loss: 0.5919 - val_acc: 0.8632\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 8s 396us/step - loss: 0.1350 - acc: 0.9623 - val_loss: 0.4668 - val_acc: 0.8644\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 8s 389us/step - loss: 0.0762 - acc: 0.9858 - val_loss: 0.4975 - val_acc: 0.8626\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 8s 395us/step - loss: 0.0641 - acc: 0.9885 - val_loss: 0.7467 - val_acc: 0.8552\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32, kernel_regularizer=regularizers.l2(0.1)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 11s 567us/step - loss: 0.6935 - acc: 0.5030 - val_loss: 0.6939 - val_acc: 0.5044\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 10s 486us/step - loss: 0.6944 - acc: 0.5129 - val_loss: 0.6898 - val_acc: 0.4952\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 10s 489us/step - loss: 0.6817 - acc: 0.5225 - val_loss: 0.7689 - val_acc: 0.5056\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 10s 496us/step - loss: 0.6716 - acc: 0.5296 - val_loss: 0.6778 - val_acc: 0.5314\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 10s 495us/step - loss: 0.6808 - acc: 0.5378 - val_loss: 0.6808 - val_acc: 0.5184\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 10s 498us/step - loss: 0.6546 - acc: 0.5804 - val_loss: 0.5656 - val_acc: 0.7336\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 10s 498us/step - loss: 0.5459 - acc: 0.7511 - val_loss: 0.5072 - val_acc: 0.7952\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 10s 496us/step - loss: 0.5130 - acc: 0.7740 - val_loss: 0.5063 - val_acc: 0.7940\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 10s 497us/step - loss: 0.5167 - acc: 0.7685 - val_loss: 0.6254 - val_acc: 0.7256\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 10s 496us/step - loss: 0.4915 - acc: 0.7946 - val_loss: 0.5578 - val_acc: 0.7426\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 10s 497us/step - loss: 0.4836 - acc: 0.8005 - val_loss: 0.5180 - val_acc: 0.8020\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 10s 497us/step - loss: 0.4739 - acc: 0.8062 - val_loss: 0.5284 - val_acc: 0.7896\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 10s 497us/step - loss: 0.4808 - acc: 0.7986 - val_loss: 0.5098 - val_acc: 0.8070\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 10s 501us/step - loss: 0.4806 - acc: 0.8000 - val_loss: 0.5541 - val_acc: 0.7988\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 10s 498us/step - loss: 0.4871 - acc: 0.7943 - val_loss: 0.5782 - val_acc: 0.7650\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 10s 496us/step - loss: 0.4980 - acc: 0.7983 - val_loss: 0.5704 - val_acc: 0.7650\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 10s 498us/step - loss: 0.4732 - acc: 0.8126 - val_loss: 0.5302 - val_acc: 0.7794\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 10s 499us/step - loss: 0.4881 - acc: 0.7976 - val_loss: 0.5224 - val_acc: 0.7812\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 10s 499us/step - loss: 0.4986 - acc: 0.7912 - val_loss: 0.5224 - val_acc: 0.8020\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 10s 498us/step - loss: 0.4742 - acc: 0.8052 - val_loss: 0.5310 - val_acc: 0.8020\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# callback : EarlyStopping & ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    \n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor = 'val_acc',\n",
    "        patience = 5,\n",
    "    ),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = 'imdb_lstm.h5',\n",
    "        monitor = 'val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 10s 476us/step - loss: 0.6929 - acc: 0.5066 - val_loss: 0.6933 - val_acc: 0.5048\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 7s 367us/step - loss: 0.6872 - acc: 0.5097 - val_loss: 0.6997 - val_acc: 0.4986\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 7s 368us/step - loss: 0.7083 - acc: 0.5224 - val_loss: 0.6917 - val_acc: 0.5150\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 7s 368us/step - loss: 0.6710 - acc: 0.5700 - val_loss: 0.6080 - val_acc: 0.6880\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 7s 370us/step - loss: 0.6065 - acc: 0.6838 - val_loss: 0.5792 - val_acc: 0.7070\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 7s 369us/step - loss: 0.5881 - acc: 0.7068 - val_loss: 0.6131 - val_acc: 0.6858\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 7s 370us/step - loss: 0.5553 - acc: 0.7493 - val_loss: 0.5365 - val_acc: 0.7676\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 8s 376us/step - loss: 0.5805 - acc: 0.7366 - val_loss: 0.5141 - val_acc: 0.7842\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 7s 374us/step - loss: 0.5247 - acc: 0.7731 - val_loss: 0.5778 - val_acc: 0.7622\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 7s 372us/step - loss: 0.5128 - acc: 0.7851 - val_loss: 0.7901 - val_acc: 0.5280\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 8s 375us/step - loss: 0.5248 - acc: 0.7699 - val_loss: 0.5403 - val_acc: 0.7698\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(16))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_15 (CuDNNLSTM)    (None, 16)                3200      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 323,217\n",
      "Trainable params: 323,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 17s 848us/step - loss: 0.6931 - acc: 0.4957 - val_loss: 0.6930 - val_acc: 0.5036\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 14s 695us/step - loss: 0.6884 - acc: 0.5153 - val_loss: 0.6860 - val_acc: 0.5206\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 14s 689us/step - loss: 0.6815 - acc: 0.5413 - val_loss: 0.7104 - val_acc: 0.5418\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 14s 689us/step - loss: 0.6685 - acc: 0.6283 - val_loss: 0.6250 - val_acc: 0.6830\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 14s 699us/step - loss: 0.5972 - acc: 0.7072 - val_loss: 0.6017 - val_acc: 0.6892\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 14s 699us/step - loss: 0.5610 - acc: 0.7422 - val_loss: 0.6019 - val_acc: 0.6970\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 14s 702us/step - loss: 0.6071 - acc: 0.7018 - val_loss: 0.5117 - val_acc: 0.7928\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 14s 701us/step - loss: 0.5407 - acc: 0.7621 - val_loss: 0.6240 - val_acc: 0.6276\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 14s 703us/step - loss: 0.5829 - acc: 0.6826 - val_loss: 0.6954 - val_acc: 0.5400\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 14s 704us/step - loss: 0.5018 - acc: 0.7777 - val_loss: 0.4886 - val_acc: 0.7920\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 14s 705us/step - loss: 0.4914 - acc: 0.7858 - val_loss: 0.5008 - val_acc: 0.7834\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 14s 717us/step - loss: 0.4891 - acc: 0.7898 - val_loss: 0.5041 - val_acc: 0.7874\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32, return_sequences=True))\n",
    "model.add(CuDNNLSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 18s 905us/step - loss: 0.6929 - acc: 0.5095 - val_loss: 0.6919 - val_acc: 0.5038\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 14s 694us/step - loss: 0.6924 - acc: 0.5184 - val_loss: 0.6683 - val_acc: 0.7104\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 14s 703us/step - loss: 0.6510 - acc: 0.6352 - val_loss: 0.6370 - val_acc: 0.6274\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 14s 703us/step - loss: 0.6043 - acc: 0.7043 - val_loss: 0.6111 - val_acc: 0.7068\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 14s 712us/step - loss: 0.5887 - acc: 0.7172 - val_loss: 0.5863 - val_acc: 0.6904\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 14s 713us/step - loss: 0.5768 - acc: 0.7339 - val_loss: 0.5347 - val_acc: 0.7514\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 14s 708us/step - loss: 0.5153 - acc: 0.7745 - val_loss: 0.5504 - val_acc: 0.7604\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 14s 711us/step - loss: 0.5621 - acc: 0.7046 - val_loss: 0.5169 - val_acc: 0.7768\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 14s 709us/step - loss: 0.5139 - acc: 0.7676 - val_loss: 0.4827 - val_acc: 0.7690\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 14s 715us/step - loss: 0.4982 - acc: 0.7715 - val_loss: 0.5004 - val_acc: 0.7886\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 14s 712us/step - loss: 0.4920 - acc: 0.7893 - val_loss: 0.4829 - val_acc: 0.7976\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 14s 708us/step - loss: 0.4736 - acc: 0.8037 - val_loss: 0.5043 - val_acc: 0.7928\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 14s 711us/step - loss: 0.4780 - acc: 0.8055 - val_loss: 0.4885 - val_acc: 0.8036\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 14s 706us/step - loss: 0.4746 - acc: 0.8111 - val_loss: 0.4785 - val_acc: 0.8022\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 14s 712us/step - loss: 0.4479 - acc: 0.8212 - val_loss: 0.4874 - val_acc: 0.7958\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 14s 710us/step - loss: 0.5780 - acc: 0.6708 - val_loss: 0.5408 - val_acc: 0.7502\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 14s 709us/step - loss: 0.4734 - acc: 0.8077 - val_loss: 0.5320 - val_acc: 0.7882\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 14s 710us/step - loss: 0.4806 - acc: 0.8092 - val_loss: 0.5313 - val_acc: 0.7914\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers,initializer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32, return_sequences=True, kernel_regularizer=regularizers.l2(1e-5)))\n",
    "model.add(CuDNNLSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# 특성으로 사용할 단어의 수\n",
    "max_features = 10000\n",
    "# 사용할 텍스트의 길이(가장 빈번한 max_features 개의 단어만 사용합니다)\n",
    "maxlen1 = 1000\n",
    "\n",
    "# 정수 리스트로 데이터를 로드합니다.\n",
    "(X_train, yy_train), (X_test, yy_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# 리스트를 (samples, maxlen) 크기의 2D 정수 텐서로 변환합니다.\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen=maxlen1,padding='post')\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test, maxlen=maxlen1,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 18s 891us/step - loss: 0.6934 - acc: 0.4981 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 14s 713us/step - loss: 0.6933 - acc: 0.5013 - val_loss: 0.6932 - val_acc: 0.5064\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 14s 714us/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6932 - val_acc: 0.4946\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 14s 710us/step - loss: 0.6932 - acc: 0.5005 - val_loss: 0.6934 - val_acc: 0.4950\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 14s 712us/step - loss: 0.6927 - acc: 0.4957 - val_loss: 0.6932 - val_acc: 0.5066\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 14s 714us/step - loss: 0.6924 - acc: 0.5010 - val_loss: 0.6933 - val_acc: 0.4946\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 14s 717us/step - loss: 0.7002 - acc: 0.4973 - val_loss: 0.6937 - val_acc: 0.4930\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 14s 720us/step - loss: 0.6940 - acc: 0.4977 - val_loss: 0.7032 - val_acc: 0.4940\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 14s 719us/step - loss: 0.6943 - acc: 0.5022 - val_loss: 0.6932 - val_acc: 0.5066\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 14s 717us/step - loss: 0.6937 - acc: 0.5050 - val_loss: 0.6930 - val_acc: 0.5068\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 14s 720us/step - loss: 0.6935 - acc: 0.4960 - val_loss: 0.6936 - val_acc: 0.4942\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 14s 715us/step - loss: 0.6945 - acc: 0.5036 - val_loss: 0.6933 - val_acc: 0.4936\n",
      "Epoch 13/20\n",
      "12544/20000 [=================>............] - ETA: 4s - loss: 0.6935 - acc: 0.4978"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-17e6bd5e80b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                    callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, yy_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import CuDNNLSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32))\n",
    "model.add(CuDNNLSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(X_train, yy_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 훈련된 단어 임베딩 사용하기\n",
    "\n",
    "이따금 훈련 데이터가 부족하면 작업에 맞는 단어 임베딩을 학습할 수 없습니다. 이럴 땐 어떻게 해야 할까요?\n",
    "\n",
    "풀려는 문제와 함께 단어 임베딩을 학습하는 대신에 미리 계산된 임베딩 공간에서 임베딩 벡터를 로드할 수 있습니다. 이런 임베딩 공간은 뛰어난 구조와 유용한 성질을 가지고 있어서 언어 구조의 일반적인 측면을 잡아낼 수 있습니다. 자연어 처리에서 사전 훈련된 단어 임베딩을 사용하는 이유는 이미지 분류 문제에서 사전 훈련된 컨브넷을 사용하는 이유와 거의 동일합니다. 충분한 데이터가 없어서 자신만의 좋은 특성을 학습하지 못하지만 꽤 일반적인 특성이 필요할 때입니다. 이런 경우에는 다른 문제에서 학습한 특성을 재사용하는 것이 합리적입니다.\n",
    "\n",
    "단어 임베딩은 일반적으로 (문장이나 문서에 같이 등장하는 단어를 관찰하는) 단어 출현 통계를 사용하여 계산됩니다. 여기에는 여러 가지 기법이 사용되는데 신경망을 사용하는 것도 있고 그렇지 않은 방법도 있습니다. 단어를 위해 밀집된 저차원 임베딩 공간을 비지도 학습 방법으로 계산하는 아이디어는 요슈아 벤지오 등이 2000년대 초에 조사했습니다. 연구나 산업 애플리케이션에 적용되기 시작된 것은 Word2vec 알고리즘이 등장한 이후입니다. 이 알고리즘은 2013년 구글의 토마스 미코로프가 개발하였으며 가장 유명하고 성공적인 단어 임베딩 방법입니다. Word2vec의 차원은 성별 같은 구체적인 의미가 있는 속성을 잡아냅니다.\n",
    "\n",
    "케라스의 `Embedding` 층을 위해 내려받을 수 있는 미리 계산된 단어 임베딩 데이터베이스가 여럿 있습니다. Word2vec은 그 중 하나입니다. 인기 있는 또 다른 하나는 2014년 스탠포드 대학의 연구자들이 개발한 GloVe(Global Vectors for Word Representation)입니다. 이 임베딩 기법은 단어의 동시 출현 통계를 기록한 행렬을 분해하는 기법을 사용합니다. 이 개발자들은 위키피디아 데이터와 커먼 크롤 데이터에서 가져온 수백만 개의 영어 토큰에 대해서 임베딩을 미리 계산해 놓았습니다.\n",
    "\n",
    "GloVe 임베딩을 케라스 모델에 어떻게 사용하는지 알아보죠. Word2vec 임베딩이나 다른 단어 임베딩 데이터베이스도 방법은 같습니다. 앞서 보았던 텍스트 토큰화 기법도 다시 살펴보겠습니다. 원본 텍스트에서 시작해서 완전한 모델을 구성해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 내용을 적용하기: 원본 텍스트에서 단어 임베딩까지\n",
    "\n",
    "앞서 만들었던 것과 비슷한 모델을 사용하겠습니다. 문장들을 벡터의 시퀀스로 임베딩하고 펼친 다음 그 위에 `Dense` 층을 훈련합니다. 여기서는 사전 훈련된 단어 임베딩을 사용하겠습니다. 케라스에 포함된 IMDB 데이터는 미리 토큰화가 되어 있습니다. 이를 사용하는 대신 원본 텍스트 데이터를 다운로딩해서 처음부터 시작하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 IMDB 텍스트 다운로드하기\n",
    "\n",
    "먼저 http://mng.bz/0tIo 에서 IMDB 원본 데이터셋을 다운로드하고 압축을 해제합니다.\n",
    "\n",
    "훈련용 리뷰 하나를 문자열 하나로 만들어 훈련 데이터를 문자열의 리스트로 구성해 보죠. 리뷰 레이블(긍정/부정)도 `labels` 리스트로 만들겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = './datasets/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf8')\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 토큰화\n",
    "\n",
    "이전 절에서 소개한 개념을 사용해 텍스트를 벡터로 만들고 훈련 세트와 검증 세트로 나누겠습니다. 사전 훈련된 단어 임베딩은 훈련 데이터가 부족한 문제에 특히 유용합니다(그렇지 않으면 문제에 특화된 임베딩이 훨씬 성능이 좋습니다). 그래서 다음과 같이 훈련 데이터를 처음 200개의 샘플로 제한합니다. 이 모델은 200개의 샘플을 학습한 후에 영화 리뷰를 분류할 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88582개의 고유한 토큰을 찾았습니다.\n",
      "데이터 텐서의 크기: (25000, 100)\n",
      "레이블 텐서의 크기: (25000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100  # 100개 단어 이후는 버립니다\n",
    "training_samples = 200  # 훈련 샘플은 200개입니다\n",
    "validation_samples = 10000  # 검증 샘플은 10,000개입니다\n",
    "max_words = 10000  # 데이터셋에서 가장 빈도 높은 10,000개의 단어만 사용합니다\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('%s개의 고유한 토큰을 찾았습니다.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print('데이터 텐서의 크기:', data.shape)\n",
    "print('레이블 텐서의 크기:', labels.shape)\n",
    "\n",
    "# 데이터를 훈련 세트와 검증 세트로 분할합니다.\n",
    "# 샘플이 순서대로 있기 때문에 (부정 샘플이 모두 나온 후에 긍정 샘플이 옵니다) \n",
    "# 먼저 데이터를 섞습니다.\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe 단어 임베딩 내려받기\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove 에서 2014년 영문 위키피디아를 사용해 사전에 계산된 임베딩을 내려받습니다. 이 파일의 이름은 glove.6B.zip이고 압축 파일 크기는 823MB입니다. 400,000만개의 단어(또는 단어가 아닌 토큰)에 대한 100차원의 임베딩 벡터를 포함하고 있습니다. datasets 폴더 아래에 파일 압축을 해제합니다.(이 저장소에는 이미 포함되어 있습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임베딩 전처리\n",
    "\n",
    "압축 해제한 파일(.txt 파일)을 파싱하여 단어(즉 문자열)와 이에 상응하는 벡터 표현(즉 숫자 벡터)를 매핑하는 인덱스를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000개의 단어 벡터를 찾았습니다.\n"
     ]
    }
   ],
   "source": [
    "glove_dir = './datasets/'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('%s개의 단어 벡터를 찾았습니다.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음 `Embedding` 층에 주입할 수 있도록 임베딩 행렬을 만듭니다. 이 행렬의 크기는 `(max_words, embedding_dim)`이어야 합니다. 이 행렬의 `i`번째 원소는 (토큰화로 만든) 단어 인덱스의 `i`번째 단어에 상응하는 `embedding_dim` 차원 벡터입니다. 인덱스 `0`은 어떤 단어나 토큰도 아닐 경우를 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # 임베딩 인덱스에 없는 단어는 모두 0이 됩니다.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의하기\n",
    "\n",
    "이전과 동일한 구조의 모델을 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델에 GloVe 임베딩 로드하기\n",
    "\n",
    "`Embedding` 층은 하나의 가중치 행렬을 가집니다. 이 행렬은 2D 부동 소수 행렬이고 각 `i`번째 원소는 `i`번째 인덱스에 상응하는 단어 벡터입니다. 간단하네요. 모델의 첫 번째 층인 `Embedding` 층에 준비된 GloVe 행렬을 로드하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가적으로 `Embedding` 층을 동결합니다(`trainable` 속성을 `False`로 설정합니다). 사전 훈련된 컨브넷 특성을 사용할 때와 같은 이유입니다. 모델의 일부는 (`Embedding` 층처럼) 사전 훈련되고 다른 부분은 (최상단 분류기처럼) 랜덤하게 초기화되었다면 훈련하는 동안 사전 훈련된 부분이 업데이트되면 안됩니다. 이미 알고 있던 정보를 모두 잃게 됩니다. 랜덤하게 초기화된 층에서 대량의 그래디언트 업데이트가 발생하면 이미 학습된 특성을 오염시키기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련과 평가\n",
    "\n",
    "모델을 컴파일하고 훈련합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.6733 - acc: 0.5400 - val_loss: 0.6907 - val_acc: 0.5338\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 964us/step - loss: 0.6077 - acc: 0.6700 - val_loss: 0.8459 - val_acc: 0.5060\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 976us/step - loss: 0.4950 - acc: 0.7650 - val_loss: 0.6870 - val_acc: 0.5583\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 990us/step - loss: 0.3349 - acc: 0.8950 - val_loss: 0.8019 - val_acc: 0.5098\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 986us/step - loss: 0.2251 - acc: 0.9600 - val_loss: 0.7647 - val_acc: 0.5462\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 983us/step - loss: 0.3254 - acc: 0.8150 - val_loss: 0.6875 - val_acc: 0.5835\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.1144 - acc: 0.9950 - val_loss: 1.0806 - val_acc: 0.5026\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1141 - acc: 0.9800 - val_loss: 0.7699 - val_acc: 0.5488\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 996us/step - loss: 0.0671 - acc: 0.9950 - val_loss: 0.7842 - val_acc: 0.5610\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 974us/step - loss: 0.0814 - acc: 0.9850 - val_loss: 1.6252 - val_acc: 0.5076\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델의 성능을 그래프로 그려 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 과대적합이 빠르게 시작됩니다. 훈련 샘플 수가 작기 때문에 놀라운 일은 아닙니다. 같은 이유로 검증 정확도와 훈련 정확도 사이에 차이가 큽니다. 검증 정확도는 50% 후반을 달성한 것 같습니다.\n",
    "\n",
    "훈련 샘플 수가 적기 때문에 어떤 샘플 200개를 선택했는지에 따라 성능이 크게 좌우됩니다. 여기서는 샘플들을 랜덤하게 선택했습니다. 만약 선택한 샘플에서 성능이 나쁘면 예제를 위해서 랜덤하게 200개의 샘플을 다시 추출하세요(실전에서는 훈련 데이터를 고르지 않습니다).\n",
    "\n",
    "사전 훈련된 단어 임베딩을 사용하지 않거나 임베딩 층을 동결하지 않고 같은 모델을 훈련할 수 있습니다. 이런 경우 해당 작업에 특화된 입력 토큰의 임베딩을 학습할 것입니다. 데이터가 풍부하게 있다면 사전 훈련된 단어 임베딩보다 일반적으로 훨씬 성능이 높습니다. 여기서는 훈련 샘플이 200개뿐이지만 한 번 시도해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6894 - acc: 0.5200 - val_loss: 0.6953 - val_acc: 0.5117\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.4895 - acc: 0.9650 - val_loss: 0.7149 - val_acc: 0.5138\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.2904 - acc: 0.9800 - val_loss: 0.7029 - val_acc: 0.5150\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1236 - acc: 1.0000 - val_loss: 0.7255 - val_acc: 0.5194\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0553 - acc: 1.0000 - val_loss: 0.7111 - val_acc: 0.5195\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.7580 - val_acc: 0.5212\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.5197\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.7509 - val_acc: 0.5228\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.7437 - val_acc: 0.5208\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 0.5243\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X14VOW57/HvzZuRF0EBRQgQUKoGBMSR6pEWVNoNvgBaVDBatbqpbq1a3ftI1XYrR66t1qOWbo6VenT31ChSrEpblLbK9qWtSEAaJYggAkYQIgXkVQjc549nQibJJJmESWYl+X2ua66ZteaZNfdMYH7zPOuZtczdERERiZpWmS5AREQkGQWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaAkY8ystZntNLM+6WybSWZ2opml/bcbZjbazNYmLK80s2+k0rYez/Wkmd1V38fXsN37zey/0r1dab7aZLoAaTrMbGfCYnvgK+BAfPn77p5fl+25+wGgY7rbtgTuflI6tmNm1wNXuvuohG1fn45tixwuBZSkzN0PBUT8G/r17v7n6tqbWRt3L22M2kSk+dEQn6RNfAjneTN7zsx2AFea2Vlm9o6ZbTOzjWY2w8zaxtu3MTM3s5z48jPx+18xsx1m9jcz61fXtvH7x5rZR2a23cx+bmZ/MbNrqqk7lRq/b2arzWyrmc1IeGxrM3vUzLaY2cfAmBren3vMbHaldTPN7JH47evNbEX89Xwc791Ut61iMxsVv93ezH4dr205cHqS510T3+5yMxsXX38q8J/AN+LDp18kvLf3Jjz+hvhr32JmL5nZ8am8N7UxswnxeraZ2etmdlLCfXeZ2QYz+9LMPkx4rWea2dL4+k1m9tNUn0+aIHfXRZc6X4C1wOhK6+4H9gEXEb78HAmcAXyd0FvvD3wE3Bxv3wZwICe+/AzwBRAD2gLPA8/Uo+2xwA5gfPy+24H9wDXVvJZUanwZ6AzkAP8oe+3AzcByIBvoCrwZ/lslfZ7+wE6gQ8K2NwOx+PJF8TYGnAvsAQbH7xsNrE3YVjEwKn77YeC/gaOBvkBRpbaXAcfH/yZXxGs4Ln7f9cB/V6rzGeDe+O1vx2scCmQB/wd4PZX3Jsnrvx/4r/jtU+J1nBv/G90Vf9/bAgOBdUCPeNt+QP/47cXA5PjtTsDXM/1/QZeGu6gHJen2trv/zt0Puvsed1/s7ovcvdTd1wCzgJE1PH6uuxe4+34gn/DBWNe2FwLL3P3l+H2PEsIsqRRr/A933+7uawlhUPZclwGPunuxu28BHqjhedYAHxCCE+BbwDZ3L4jf/zt3X+PB68BrQNKJEJVcBtzv7lvdfR2hV5T4vHPcfWP8b/Is4ctFLIXtAuQBT7r7MnffC0wFRppZdkKb6t6bmkwC5rn76/G/0QPAUYQvCqWEMBwYHyb+JP7eQfiiMcDMurr7DndflOLrkCZIASXp9mnigpmdbGZ/MLPPzexLYBrQrYbHf55wezc1T4yorm3PxDrc3Qk9jqRSrDGl5yJ886/Js8Dk+O0rCMFaVseFZrbIzP5hZtsIvZea3qsyx9dUg5ldY2Z/jw+lbQNOTnG7EF7foe25+5fAVqBXQpu6/M2q2+5Bwt+ol7uvBO4g/B02x4eMe8SbXgvkAivN7F0zOz/F1yFNkAJK0q3yFOsnCL2GE939KOAnhCGshrSRMOQGgJkZFT9QKzucGjcCvROWa5sG/zwwOt4DGU8ILMzsSGAu8B+E4bcuwB9TrOPz6mows/7A48CNQNf4dj9M2G5tU+I3EIYNy7bXiTCU+FkKddVlu60If7PPANz9GXc/mzC815rwvuDuK919EmEY938DL5hZ1mHWIhGlgJKG1gnYDuwys1OA7zfCc/4eGGZmF5lZG+BWoHsD1TgHuM3MeplZV+DOmhq7+ybgbeBpYKW7r4rfdQTQDigBDpjZhcB5dajhLjPrYuF3Yjcn3NeREEIlhKy+ntCDKrMJyC6bFJLEc8B1ZjbYzI4gBMVb7l5tj7QONY8zs1Hx5/43wn7DRWZ2ipmdE3++PfHLAcILuMrMusV7XNvjr+3gYdYiEaWAkoZ2B3A14cPnCUIPokHFQ+By4BFgC3AC8B7hd1vprvFxwr6i9wk78Oem8JhnCZMenk2oeRvwQ+BFwkSDiYSgTcW/E3pya4FXgP+XsN1CYAbwbrzNyUDifps/AauATWaWOFRX9vhXCUNtL8Yf34ewX+qwuPtywnv+OCE8xwDj4vujjgAeIuw3/JzQY7sn/tDzgRUWZok+DFzu7vsOtx6JJgvD8yLNl5m1JgwpTXT3tzJdj4ikRj0oaZbMbIyZdY4PE/2YMDPs3QyXJSJ1oICS5moEsIYwTDQGmODu1Q3xiUgEaYhPREQiST0oERGJpIwdLLZbt26ek5OTqacXEZEMWbJkyRfuXtNPP4AMBlROTg4FBQWZenoREckQM6vtiCuAhvhERCSiFFAiIhJJCigREYkkBZSIiESSAkpERCJJASUiIpGkgBIRkUhSQImISCRl7Ie6InJ4Pv0U5syBN96Avn1h8GA49VQYNAg6pnLSdZFa7NgBGzfC55+H640bYfTo8G+sMSigRJqQDRvgN7+B55+Hv/0trBswABYuhJ07y9udcEIIrLLQGjwY+veH1q0zU7dEx8GD8MUX5YGTGD6Vb+/aVfXxM2cqoEQkbvNmmDs3hNJbb4E7DBkC06fDZZfBiSeGD51166CwsPzy/vvw8svhPoD27cMHS1lglYVX166ZfX0Nbdeu8N588gmsXVt+vWsXdOoULkcdVfG6pnVZWWCW6VdV1d69IVRqCpyNG2HTJjhwoOrjjzoKjj8+XM44o/x2jx4Vbx9zTOO9poydbiMWi7mOxSeS3JYt8NvfhlBauDCEzCmnwKRJIZROPjm17ezeDUVF5YFVFl5ffFHepmfP8sAqu5x0ErRr1zCvLd327oX166sGUNn15s0V22dlQU5OCJwdO8Llyy9DDzSVj8PWrVMLslTWtW9fc9i5w/btqfV2tm6t+ngzOPbY8oBJFjhl1+3bp/6eHy4zW+LusVrbKaBEomHbNnjppRBKf/4zlJaG3tHll4fLoEHp+ebuHr5FJ/a2CgthxQrYty+0adMmBGLlYcKePRu/97B/f9jfVl0AbdhQsX3btmGfXL9+IYgqXx93XPLXcPBgCPQvvywPrcQAq8u6HTvKe641adWqamh16hR6d2XBs3dv1cdlZVUfNom3u3cPf8uoUUCJNAE7dsC8eSGUFiwIAZGTE3pJl18Op53WeIGwfz989FHFIcLCwhAOZY45pmJgDR4MAwdChw71f94DB+Czz5KHzyefQHFxxQ/71q2hd++q4VN2+/jjM7+vzT2EXX3C7csvQ2+mpuDp3Dmaw4ypUkCJRNSuXfCHP4RQmj8/fEPu1as8lIYPj9aHz9atIawShwjff798B7pZxUkZZQHWv3/oIRw8GHoC1QXQ+vWht1jGLLwfyXo//fpBdnY0ewWSOgWUSITs3QuvvBJC6Xe/C9+ue/SAiRPDfqWzzgof5k3FwYMhYCpPyli1qnw/TocO4TUWF8NXX1V8fI8e1QdQ795wxBGN+3qkcaUaUPoeItJA9u2DP/4xhNLLL4fhm27d4KqrQk/pm9/M/FBUfbVqFXpI/fvDhAnl63fvhuXLywPr88/hkksqBlDfvnDkkRkrXZoQBZRk1NatYed8UVG4hjC807NnuC67nZWV2TpTtX8/vP56CKUXXwwTH44+OgzfXXYZnHtu8x6eat8+TFE+44xMVyLNQTP+ryJRUlJSHkJFReWXjRvL22RlhW/mu3dXffwxx5QHVrIA69UrzFjKxDDZgQPhaA7PPw8vvBCmiHfqBBdfHHpKo0c3nSnbIlGigJK0cQ9DOokBVHZJ/N1Nx46Qmwv/9E/huuzSt2/YQb59e5jVtWFDuC67lC3//e9hmnTlabxt24YZTsnCK3E5HYcBOngQ/vKXEEpz54Z6OnSAiy4KoTRmTNPp9YlElQIqDcp+V7JqFaxeHa5LSsIv9I89Nvzu4thjyy9R/W1CqtzD1ONkPaJt28rbdekSpiBffHH4TU1ZEGVn1zxLrUuX8sdWp7Q0vOeVw6vsUlQEf/pTmLJb2VFHVR9eZbePO67q38gdFi0KofSb34TnycqCCy4IoXTBBY37Y0eR5q4Jf0w2rrLeQWIIrV5dfkk8DlqbNmFn+JYtYZ9EMmXhlSzAKi936pSZacdlM7Uq94ZWrKj4ert3D8EzeXLFHlF1P4hMhzZtysOkJjt3Vt8T++yzcJSGjRsrTnOGMFR43HHlz3H00aHtunVhuG7MGHjoodBj6tSpYV6jSEuX0jRzMxsD/AxoDTzp7g9Uuv9R4Jz4YnvgWHfvUtM2ozjN3D18WCWGT+LtxAMntmkTZjCdeGI4WGfidd++4f6yw5Rs3hwumzaV3062nOxQJRC+pdcUYInL3bqFoa66KC2Fjz+u2iP68EPYs6e8Xc+eFXtCublhuXv3ur/XUXLwYOjx1jSsuGkTnH566ClNmBB+KCki9ZO230GZWWvgI+BbQDGwGJjs7kXVtP8BcJq7f6+m7WYqoNzDh05i+CSGUOIO+rZtqw+hPn3SP0y3b1/4oEwlzDZtSq13lizQSksr9og++qj8EDcQXltiCJUFUZcav3KIiKQmnb+DGg6sdvc18Q3PBsYDSQMKmAz8e6qFNoSDB2sOocReQdu24VfwJ54I550XrsuCqHfvxt1X1K5dasNWULF3VlOYFRaG5cR9QxCG3vr3D8Fz/vnlQXTyyRqyEpFoSOXjtxeQcDQuioGvJ2toZn2BfsDr1dw/BZgC0KdPnzoVWtmvfw0/+lEYfjnmmPBL/HbtQhB9/HHFEGrXLnwYDxgQpvwm9oZ6926aP5Y0K59M8LWv1d4+sXdmFo5WrR9LikiUpRJQyXZzVzcuOAmY6+5JzjYC7j4LmAVhiC+lCpPIz4d//ufyw6f84x/h2GY9e0IsBt/+dsUQys5umiGUTnXpnYmIREEqAVUM9E5YzgY2VNN2EnDT4RZVm7vvrnpsLwjDdS+/3NDPLiIijSGV390vBgaYWT8za0cIoXmVG5nZScDRwN/SW2JV69fXbb2IiDQ9tQaUu5cCNwMLgBXAHHdfbmbTzGxcQtPJwGxvhMOjV7f76jB3a4mISISkNEfN3ecD8yut+0ml5XvTV1bNpk+HKVMqTglv3z6sFxGR5qEJnYGmXF4ezJpVfuy2vn3Dcl5episTEZF0abKHOsrLUyCJiDRnTbIHJSIizZ8CSkREIkkBJSIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiERSSgFlZmPMbKWZrTazqdW0uczMisxsuZk9m94yRUSkpan1lO9m1hqYCXwLKAYWm9k8dy9KaDMA+BFwtrtvNbNjG6pgERFpGVLpQQ0HVrv7GnffB8wGxldq88/ATHffCuDum9NbpoiItDSpBFQv4NOE5eL4ukRfA75mZn8xs3fMbEyyDZnZFDMrMLOCkpKS+lUsIiItQioBZUnWeaXlNsAAYBQwGXjSzLpUeZD7LHePuXuse/fuda1VRERakFQCqhjonbCcDWxI0uZld9/v7p8AKwmBJSIiUi+pBNRiYICZ9TOzdsAkYF6lNi8B5wCYWTfCkN+adBYqIiItS60B5e6lwM3AAmAFMMfdl5vZNDMbF2+2ANhiZkXAQuDf3H1LQxUtIiLNn7lX3p3UOGKxmBcUFGTkuUVEJHPMbIm7x2prpyNJiIhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiESSAkpERCJJASUiIpGkgBIRkUhSQImISCQpoEREJJIUUCIiEkkpBZSZjTGzlWa22symJrn/GjMrMbNl8cv16S9VRERakja1NTCz1sBM4FtAMbDYzOa5e1Glps+7+80NUKOIiLRAqfSghgOr3X2Nu+8DZgPjG7YsERFp6VIJqF7ApwnLxfF1lX3HzArNbK6Z9U5LdU1Qfj7k5ECrVuE6Pz/TFYmINE2pBJQlWeeVln8H5Lj7YODPwK+SbshsipkVmFlBSUlJ3SptAvLzYcoUWLcO3MP1lCkKKRGR+kgloIqBxB5RNrAhsYG7b3H3r+KLvwROT7Yhd5/l7jF3j3Xv3r0+9Uba3XfD7t0V1+3eHdaLiEjdpBJQi4EBZtbPzNoBk4B5iQ3M7PiExXHAivSV2HSsX1+39SIiUr1aZ/G5e6mZ3QwsAFoDT7n7cjObBhS4+zzgFjMbB5QC/wCuacCaI6tPnzCsl2y9iIjUjblX3p3UOGKxmBcUFGTkuRtK2T6oxGG+9u1h1izIy8tcXSIiUWJmS9w9Vls7HUkijfLyQhj17Qtm4VrhJCJSP7UO8Und5OUpkERE0kE9KBERiSQFlIiIRJICSkREIkkBJSIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYmklALKzMaY2UozW21mU2toN9HM3MxqPde8iIhITWoNKDNrDcwExgK5wGQzy03SrhNwC7Ao3UWKiEjLk0oPajiw2t3XuPs+YDYwPkm7/wU8BOxNY30iItJCpRJQvYBPE5aL4+sOMbPTgN7u/vs01iYiIi1YKgFlSdb5oTvNWgGPAnfUuiGzKWZWYGYFJSUlqVcpIiItTioBVQz0TljOBjYkLHcCBgH/bWZrgTOBeckmSrj7LHePuXuse/fu9a9aRESavVQCajEwwMz6mVk7YBIwr+xOd9/u7t3cPcfdc4B3gHHuXtAgFYuISItQa0C5eylwM7AAWAHMcfflZjbNzMY1dIEiItIytUmlkbvPB+ZXWveTatqOOvyyRESkpdORJEREJJIUUCIiEkkKKBERiSQFlIiIRJICSkREIkkBJSIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiERSSgFlZmPMbKWZrTazqUnuv8HM3jezZWb2tpnlpr9UERFpSWoNKDNrDcwExgK5wOQkAfSsu5/q7kOBh4BH0l6piIi0KKn0oIYDq919jbvvA2YD4xMbuPuXCYsdAE9fiZIu+fmQkwOtWoXr/PxMVyQiUr02KbTpBXyasFwMfL1yIzO7CbgdaAecm2xDZjYFmALQp0+futYqhyE/H6ZMgd27w/K6dWEZIC8vc3WJiFQnlR6UJVlXpYfk7jPd/QTgTuCeZBty91nuHnP3WPfu3etWqRyWu+8uD6cyu3eH9SIiUZRKQBUDvROWs4ENNbSfDUw4nKIk/davr9t6EZFMSyWgFgMDzKyfmbUDJgHzEhuY2YCExQuAVekrUdKhuhFVjbSKSFTVGlDuXgrcDCwAVgBz3H25mU0zs3HxZjeb2XIzW0bYD3V1g1Us9TJ9OrRvX3Fd+/ZhvYhIFKUySQJ3nw/Mr7TuJwm3b01zXZJmZRMh7r47DOv16RPCSRMkRCSqUgooaR7y8hRIItJ06FBHIiISSQooERGJJAWUiIhEkgJKREQiSQElIiKRpIASEZFIUkCJiEgkKaBERCSSFFAiIhJJCigREYkkBZSIiESSAkpERCJJASUiIpGkgBIRkUhSQImISCQpoEREJJIUUCIiEkkKKBERiaSUAsrMxpjZSjNbbWZTk9x/u5kVmVmhmb1mZn3TX6qIiLQktQaUmbUGZgJjgVxgspnlVmr2HhBz98HAXOChdBcqIiItSyo9qOHAandf4+77gNnA+MQG7r7Q3XfHF98BstNbpoiItDSpBFQv4NOE5eL4uupcB7yS7A4zm2JmBWZWUFJSknqVIiLS4qQSUJZknSdtaHYlEAN+mux+d5/l7jF3j3Xv3j31KkVEpMVpk0KbYqB3wnI2sKFyIzMbDdwNjHT3r9JTnoiItFSp9KAWAwPMrJ+ZtQMmAfMSG5jZacATwDh335z+MkVEpKWpNaDcvRS4GVgArADmuPtyM5tmZuPizX4KdAR+Y2bLzGxeNZsTERFJSSpDfLj7fGB+pXU/Sbg9Os11iYhIC6cjSYiISCQpoEREJJIUUCIiEkkKKBERiSQFlIiIRJICSkREIkkBJSIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUREJ+PuTkQKtW4To/P9MViUimpXQ0c5GGlJ8PU6bA7t1hed26sAyQl5e5ukQks9SDkoy7++7ycCqze3dYLyItlwJKMm79+rqtF5GWQQElGdenT93Wi0jLoICSjJs+Hdq3r7iuffuwXkRaLgWUZFxeHsyaBX37glm4njVLEyREWrqUAsrMxpjZSjNbbWZTk9z/TTNbamalZjYx/WVKc5eXB2vXwsGD4VrhJCK1BpSZtQZmAmOBXGCymeVWarYeuAZ4Nt0FiohIy5TK76CGA6vdfQ2Amc0GxgNFZQ3cfW38voMNUKOIiLRAqQRUL+DThOVi4Ov1eTIzmwJMAeiTZIrW/v37KS4uZu/evfXZvDSyrKwssrOzadu2baZLEZFmKJWAsiTrvD5P5u6zgFkAsVisyjaKi4vp1KkTOTk5mCV7WokKd2fLli0UFxfTr1+/TJcjIs1QKpMkioHeCcvZwIaGKGbv3r107dpV4dQEmBldu3ZVb1dEGkwqAbUYGGBm/cysHTAJmNdQBSmcmg79rUSkIdUaUO5eCtwMLABWAHPcfbmZTTOzcQBmdoaZFQOXAk+Y2fKGLFpERJq/lH4H5e7z3f1r7n6Cu0+Pr/uJu8+L317s7tnu3sHdu7r7wIYsuky6T9GwZcsWhg4dytChQ+nRowe9evU6tLxv376UtnHttdeycuXKGtvMnDmT/DSdT2LEiBEsW7YsLdsSEYmSJnu6jYY4RUPXrl0Pfdjfe++9dOzYkX/913+t0MbdcXdatUqe7U8//XStz3PTTTfVr0ARkRakyR7qqDFP0bB69WoGDRrEDTfcwLBhw9i4cSNTpkwhFosxcOBApk2bdqhtWY+mtLSULl26MHXqVIYMGcJZZ53F5s2bAbjnnnt47LHHDrWfOnUqw4cP56STTuKvf/0rALt27eI73/kOQ4YMYfLkycRisVp7Ss888wynnnoqgwYN4q677gKgtLSUq6666tD6GTNmAPDoo4+Sm5vLkCFDuPLKK9P+nomIHK4m24Nq7FM0FBUV8fTTT/OLX/wCgAceeIBjjjmG0tJSzjnnHCZOnEhubsUDbGzfvp2RI0fywAMPcPvtt/PUU08xdWqVI0Xh7rz77rvMmzePadOm8eqrr/Lzn/+cHj168MILL/D3v/+dYcOG1VhfcXEx99xzDwUFBXTu3JnRo0fz+9//nu7du/PFF1/w/vvvA7Bt2zYAHnroIdatW0e7du0OrRMRiZIm24Nq7FM0nHDCCZxxxhmHlp977jmGDRvGsGHDWLFiBUVFRVUec+SRRzJ27FgATj/9dNauXZt025dcckmVNm+//TaTJk0CYMiQIQwcWPNuvUWLFnHuuefSrVs32rZtyxVXXMGbb77JiSeeyMqVK7n11ltZsGABnTt3BmDgwIFceeWV5Ofn64e2IhJJTTagGvsUDR06dDh0e9WqVfzsZz/j9ddfp7CwkDFjxiT9PVC7du0O3W7dujWlpaVJt33EEUdUaeNet99CV9e+a9euFBYWMmLECGbMmMH3v/99ABYsWMANN9zAu+++SywW48CBA3V6vpYk3ZNxRCQ1TTagMnmKhi+//JJOnTpx1FFHsXHjRhYsWJD25xgxYgRz5swB4P3330/aQ0t05plnsnDhQrZs2UJpaSmzZ89m5MiRlJSU4O5ceuml3HfffSxdupQDBw5QXFzMueeey09/+lNKSkrYXXmHngDlk3HWrQP38sk4CimRhtdk90FBCKNMnJZh2LBh5ObmMmjQIPr378/ZZ5+d9uf4wQ9+wHe/+10GDx7MsGHDGDRo0KHhuWSys7OZNm0ao0aNwt256KKLuOCCC1i6dCnXXXcd7o6Z8eCDD1JaWsoVV1zBjh07OHjwIHfeeSedOnVK+2toDmqajKNTgog0LKvrUFK6xGIxLygoqLBuxYoVnHLKKRmpJ2pKS0spLS0lKyuLVatW8e1vf5tVq1bRpk20vlM0979Zq1ah51SZWTh3lYjUnZktcfdYbe2i9Wknh+zcuZPzzjuP0tJS3J0nnngicuHUEvTpE4b1kq0XkYalT7yI6tKlC0uWLMl0GS3e9OkVfxAODTsZR0TKNdlJEiKNIZOTcURaOgWUSC3y8mDt2rDPae3a6ISTpr9Lc6chPpEmqCGORSkSNepBiTRBjXksSpFMUUAlGDVqVJUf3T722GP8y7/8S42P69ixIwAbNmxg4sSJ1W678rT6yh577LEKP5g9//zz03KcvHvvvZeHH374sLcj0dHYx6IUyQQFVILJkycze/bsCutmz57N5MmTU3p8z549mTt3br2fv3JAzZ8/ny5dutR7e9J8NfaxKOtK+8ckHSK7D+q22yDd5+EbOhTiZ7lIauLEidxzzz189dVXHHHEEaxdu5YNGzYwYsQIdu7cyfjx49m6dSv79+/n/vvvZ/z48RUev3btWi688EI++OAD9uzZw7XXXktRURGnnHIKe/bsOdTuxhtvZPHixezZs4eJEydy3333MWPGDDZs2MA555xDt27dWLhwITk5ORQUFNCtWzceeeQRnnrqKQCuv/56brvtNtauXcvYsWMZMWIEf/3rX+nVqxcvv/wyRx55ZLWvcdmyZdxwww3s3r2bE044gaeeeoqjjz6aGTNm8Itf/II2bdqQm5vL7NmzeeONN7j11luBcHr3N998U0eciIgoT3/X/jFJF/WgEnTt2pXhw4fz6quvAqH3dPnll2NmZGVl8eKLL7J06VIWLlzIHXcaZYKPAAAIHklEQVTcUeMBXR9//HHat29PYWEhd999d4XfNE2fPp2CggIKCwt54403KCws5JZbbqFnz54sXLiQhQsXVtjWkiVLePrpp1m0aBHvvPMOv/zlL3nvvfeAcODam266ieXLl9OlSxdeeOGFGl/jd7/7XR588EEKCws59dRTue+++4Bw+pD33nuPwsLCQ6cUefjhh5k5cybLli3jrbfeqjH4pHFFefp71PePqXfXdES2B1VTT6chlQ3zjR8/ntmzZx/qtbg7d911F2+++SatWrXis88+Y9OmTfTo0SPpdt58801uueUWAAYPHszgwYMP3TdnzhxmzZpFaWkpGzdupKioqML9lb399ttcfPHFh46ofskll/DWW28xbtw4+vXrx9ChQ4GaT+kB4fxU27ZtY+TIkQBcffXVXHrppYdqzMvLY8KECUyYMAGAs88+m9tvv528vDwuueQSsrOzU3kLpZFk6liUtYny/rGo9+7y80OQr18fhmunT49GXZCZ2lLqQZnZGDNbaWarzazKGffM7Agzez5+/yIzy0l3oY1lwoQJvPbaayxdupQ9e/YcOlFgfn4+JSUlLFmyhGXLlnHcccclPcVGIjOrsu6TTz7h4Ycf5rXXXqOwsJALLrig1u3U1FMrO1UH1HxKj9r84Q9/4KabbmLJkiWcfvrplJaWMnXqVJ588kn27NnDmWeeyYcfflivbUvLEuX9Y1Hu3UX5yPmZqq3WgDKz1sBMYCyQC0w2s9xKza4Dtrr7icCjwIPpLrSxdOzYkVGjRvG9732vwuSI7du3c+yxx9K2bVsWLlzIumQHaEvwzW9+k/z4X++DDz6gsLAQCKfq6NChA507d2bTpk288sorhx7TqVMnduzYkXRbL730Ert372bXrl28+OKLfOMb36jza+vcuTNHH300b731FgC//vWvGTlyJAcPHuTTTz/lnHPO4aGHHmLbtm3s3LmTjz/+mFNPPZU777yTWCymgJKUNPa52uoiyr27KIdnpmpLZYhvOLDa3dcAmNlsYDyQeIKi8cC98dtzgf80M/NMHSr9ME2ePJlLLrmkwoy+vLw8LrroImKxGEOHDuXkk0+ucRs33ngj1157LYMHD2bo0KEMHz4cCGfHPe200xg4cGCVU3VMmTKFsWPHcvzxx1fYDzVs2DCuueaaQ9u4/vrrOe2002oczqvOr371q0OTJPr378/TTz/NgQMHuPLKK9m+fTvuzg9/+EO6dOnCj3/8YxYuXEjr1q3Jzc09dHZgkZqUDftEcagqygf/jXJ4Zqq2Wk+3YWYTgTHufn18+Srg6+5+c0KbD+JtiuPLH8fbfFFpW1OAKQB9+vQ5vXIvpLmfuqE50t9MmpLK+6Ag9O6iMMEkJyd5ePbtGw6xlUnpri3V022ksg+q6o4UqJxqqbTB3We5e8zdY927d0/hqUVE0ifKsx+jPDSaqdpSCahioHfCcjawobo2ZtYG6Az8Ix0FioikU1QP/hvl8MxUbansg1oMDDCzfsBnwCTgikpt5gFXA38DJgKv13f/U9mpySX6muguRpHIiupPByAztdXag3L3UuBmYAGwApjj7svNbJqZjYs3+79AVzNbDdwOVJmKnoqsrCy2bNmiD74mwN3ZsmULWVlZmS5FRJqpWidJNJRYLOaVD566f/9+iouLa/1dkERDVlYW2dnZtG3bNtOliEgTkuokiUgdSaJt27b069cv02WIiEgE6Fh8IiISSQooERGJJAWUiIhEUsYmSZhZCVDzAe2atm7AF7W2ksr0vtWd3rP60ftWP+l43/q6e61Ha8hYQDV3ZlaQyiwVqUjvW93pPasfvW/105jvm4b4REQkkhRQIiISSQqohjMr0wU0UXrf6k7vWf3ofaufRnvftA9KREQiST0oERGJJAWUiIhEkgIqzcyst5ktNLMVZrbczG7NdE1NhZm1NrP3zOz3ma6lqTCzLmY218w+jP+bOyvTNTUFZvbD+P/PD8zsOTPTYfkrMbOnzGxz/IzpZeuOMbM/mdmq+PXRDVmDAir9SoE73P0U4EzgJjPLzXBNTcWthFO6SOp+Brzq7icDQ9D7Vysz6wXcAsTcfRDQmnCeO6nov4AxldZNBV5z9wHAa9Tz1EqpUkClmbtvdPel8ds7CB8YvTJbVfSZWTZwAfBkpmtpKszsKOCbhPOx4e773H1bZqtqMtoAR8bPAN6eqmcJb/Hc/U2qnhl9PPCr+O1fARMasgYFVAMysxzgNGBRZitpEh4D/idwMNOFNCH9gRLg6fjQ6JNm1iHTRUWdu38GPAysBzYC2939j5mtqsk4zt03QvgyDhzbkE+mgGogZtYReAG4zd2/zHQ9UWZmFwKb3X1JpmtpYtoAw4DH3f00YBcNPOTSHMT3m4wH+gE9gQ5mdmVmq5JkFFANwMzaEsIp391/m+l6moCzgXFmthaYDZxrZs9ktqQmoRgodveyHvpcQmBJzUYDn7h7ibvvB34L/I8M19RUbDKz4wHi15sb8skUUGlmZkbYJ7DC3R/JdD1Ngbv/yN2z3T2HsLP6dXfXN9pauPvnwKdmdlJ81XlAUQZLairWA2eaWfv4/9fz0OSSVM0Dro7fvhp4uSGfLFKnfG8mzgauAt43s2XxdXe5+/wM1iTN1w+AfDNrB6wBrs1wPZHn7ovMbC6wlDDr9j102KMqzOw5YBTQzcyKgX8HHgDmmNl1hKC/tEFr0KGOREQkijTEJyIikaSAEhGRSFJAiYhIJCmgREQkkhRQIiISSQooERGJJAWUiIhE0v8H9cdUImPOpG4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검증 정확도는 50% 초반에 멈추어 있습니다. 이 예제에서는 사전 훈련된 단어 임베딩을 사용하는 것이 임베딩을 함께 훈련하는 것보다 낫습니다. 훈련 샘플의 수를 늘리면 금새 상황이 바뀝니다. 연습삼아 한 번 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 샘플의 수를 2000개로 늘려서 확인해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = 2000\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 0s 181us/step - loss: 0.6383 - acc: 0.6060 - val_loss: 0.6543 - val_acc: 0.6142\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 0s 177us/step - loss: 0.1578 - acc: 0.9880 - val_loss: 0.6246 - val_acc: 0.6631\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 0s 169us/step - loss: 0.0191 - acc: 0.9995 - val_loss: 0.6568 - val_acc: 0.6787\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 0s 168us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.7071 - val_acc: 0.6916\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 0s 167us/step - loss: 1.2005e-04 - acc: 1.0000 - val_loss: 0.7635 - val_acc: 0.6972\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 0s 174us/step - loss: 8.1684e-06 - acc: 1.0000 - val_loss: 0.8398 - val_acc: 0.7043\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 0s 172us/step - loss: 7.4167e-07 - acc: 1.0000 - val_loss: 0.9032 - val_acc: 0.7046\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 0s 171us/step - loss: 1.7394e-07 - acc: 1.0000 - val_loss: 0.9660 - val_acc: 0.7040\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 0s 177us/step - loss: 1.1575e-07 - acc: 1.0000 - val_loss: 0.9998 - val_acc: 0.7039\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 0s 173us/step - loss: 1.1111e-07 - acc: 1.0000 - val_loss: 1.0030 - val_acc: 0.7046\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 샘플의 수를 늘리니 단어 임베딩을 같이 훈련하는 모델의 검증 정확도가 70%를 넘었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 테스트 데이터에서 모델을 평가해 보죠. 먼저 테스트 데이터를 토큰화해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = os.path.join(imdb_dir, 'test')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(test_dir, label_type)\n",
    "    for fname in sorted(os.listdir(dir_name)):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname), encoding=\"utf8\")\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "x_test = pad_sequences(sequences, maxlen=maxlen)\n",
    "y_test = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음 이 절의 첫 번째 모델을 로드하고 평가합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 0s 19us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6611276818060874, 0.50412]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('pre_trained_glove_model.h5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 정확도는 겨우 50% 정도입니다. 적은 수의 훈련 샘플로 작업하는 것은 어려운 일이군요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
