{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot word vectors\n",
    "- 데이터가 늘어남\n",
    "- Sparse\n",
    "- High-demensional\n",
    "- Hard-coded\n",
    "    \n",
    "## Word embeddings\n",
    "- one-hot encoding 한후-> word embedding\n",
    "- embedied layer를 통과시키면, 가중치 조합으로 변함\n",
    "- Dense\n",
    "- Lower-demensinal\n",
    "- Learned from data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "# 특성으로 사용할 단어의수\n",
    "max_features = 10000\n",
    "# 텍스트 길이 (가장 빈번한 max_feature개의 단어만 사용)\n",
    "max_len = 500\n",
    "\n",
    "(X_train, y_train),(X_test,y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# padding을 넣어 텍스트의 길이를 맞춰줌\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train,maxlen = max_len)\n",
    "X_test = preprocessing.sequence.pad_sequences(X_test,maxlen = max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding layer 및 모델 프레임 워크\n",
    "- embedding layer은 input = (samples, sequence_length) 2D 정수 텐서\n",
    "- ouput = (samples,sequence_length, embedding_demensionality) / 3D 실수형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4001      \n",
      "=================================================================\n",
      "Total params: 84,001\n",
      "Trainable params: 84,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 나중에 Embedding된 입력을 Flatten 하기위해 \n",
    "# input_length 가 없으면 (None,None,8)이 되어 Flatten() 불가능\n",
    "# Embedding층의 출력 크기는 (samples,max_len,8)\n",
    "model.add(Embedding(input_dim = max_features, output_dim = 8, input_length = max_len))\n",
    "\n",
    "# 3D Embedding tensor를 (samples,max_len*8) 2D tensor로 펼침\n",
    "model.add(Flatten())\n",
    "# 분류기 추가\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss = 'binary_crossentropy',metrics=['acc'])\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습층 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Embedding(input_dim = max_features, output_dim = 8, input_length = max_len))\n",
    "model1.add(Flatten())\n",
    "\n",
    "# 학습층 추가\n",
    "model1.add(Dense(32,activation='relu'))\n",
    "\n",
    "# 분류기 추가\n",
    "model1.add(Dense(1,activation = 'sigmoid'))\n",
    "model1.compile(optimizer='rmsprop',loss = 'binary_crossentropy',metrics=['acc'])\n",
    "model1.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 172us/step - loss: 0.4653 - acc: 0.7560 - val_loss: 0.3654 - val_acc: 0.8380\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.2199 - acc: 0.9136 - val_loss: 0.3309 - val_acc: 0.8618\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.1442 - acc: 0.9467 - val_loss: 0.3225 - val_acc: 0.8752\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.0880 - acc: 0.9692 - val_loss: 0.3785 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0505 - acc: 0.9839 - val_loss: 0.5020 - val_acc: 0.8586\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.0268 - acc: 0.9921 - val_loss: 0.6555 - val_acc: 0.8526\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 128us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.8325 - val_acc: 0.8460\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 129us/step - loss: 0.0058 - acc: 0.9985 - val_loss: 1.0204 - val_acc: 0.8344\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0025 - acc: 0.9991 - val_loss: 1.3140 - val_acc: 0.8272\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 132us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 1.4714 - val_acc: 0.8252\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(X_train,y_train, epochs = 10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지금까진 Sequence API \n",
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.4818 - acc: 0.7388 - val_loss: 0.3113 - val_acc: 0.8660\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.2254 - acc: 0.9111 - val_loss: 0.2871 - val_acc: 0.8810\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 134us/step - loss: 0.1456 - acc: 0.9447 - val_loss: 0.3252 - val_acc: 0.8766\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 135us/step - loss: 0.0912 - acc: 0.9681 - val_loss: 0.3832 - val_acc: 0.8698\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.0538 - acc: 0.9819 - val_loss: 0.4848 - val_acc: 0.8582\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 131us/step - loss: 0.0293 - acc: 0.9912 - val_loss: 0.6231 - val_acc: 0.8550\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0140 - acc: 0.9953 - val_loss: 0.8293 - val_acc: 0.8436\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0069 - acc: 0.9974 - val_loss: 0.9508 - val_acc: 0.8464\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 133us/step - loss: 0.0033 - acc: 0.9991 - val_loss: 1.1639 - val_acc: 0.8372\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 130us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 1.3391 - val_acc: 0.8352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22a98f7f780>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input,Dense,Embedding,Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(None,))\n",
    "embedding = Embedding(input_dim = max_features,output_dim = 8, input_length = max_len)(inputs)\n",
    "output1 = Flatten()(embedding)\n",
    "output2 = Dense(32,activation = 'relu')(output1)\n",
    "predictions = Dense(1,activation='sigmoid')(output2)\n",
    "api_model = Model(inputs=inputs,outputs = predictions)\n",
    "\n",
    "api_model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n",
    "\n",
    "api_model.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "api_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 규제방식\n",
    "\n",
    "1. hidden node,layer의 수\n",
    "2. L2,L1규제 -> keras regularizer\n",
    "3. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                128032    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,065\n",
      "Trainable params: 208,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 3s 166us/step - loss: 0.5113 - acc: 0.7517 - val_loss: 0.3547 - val_acc: 0.8722\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 3s 159us/step - loss: 0.2932 - acc: 0.9003 - val_loss: 0.3242 - val_acc: 0.8848\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 3s 153us/step - loss: 0.2305 - acc: 0.9276 - val_loss: 0.3306 - val_acc: 0.8796\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.1877 - acc: 0.9485 - val_loss: 0.3367 - val_acc: 0.8816\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.1503 - acc: 0.9643 - val_loss: 0.3686 - val_acc: 0.8758\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.1188 - acc: 0.9750 - val_loss: 0.3827 - val_acc: 0.8782\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 3s 154us/step - loss: 0.0929 - acc: 0.9835 - val_loss: 0.4343 - val_acc: 0.8668\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.0739 - acc: 0.9890 - val_loss: 0.4526 - val_acc: 0.8718\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 3s 149us/step - loss: 0.0619 - acc: 0.9909 - val_loss: 0.4953 - val_acc: 0.8638\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 3s 151us/step - loss: 0.0502 - acc: 0.9937 - val_loss: 0.5079 - val_acc: 0.8610\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,Embedding\n",
    "from keras import regularizers\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim = max_features, output_dim = 8, input_length = max_len))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(32,activation='relu',kernel_regularizer = regularizers.l2(0.001)))\n",
    "\n",
    "model2.add(Dense(1,activation = 'sigmoid'))\n",
    "model2.compile(optimizer='rmsprop',loss = 'binary_crossentropy',metrics=['acc'])\n",
    "model2.summary()\n",
    "\n",
    "history2 = model2.fit(X_train,y_train,epochs=10,batch_size=32,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 45us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8511999845504761"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss2,test_acc2 = model2.evaluate(X_test,y_test)\n",
    "test_acc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout 추가 ,l2규제 강화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 500, 8)            80000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 4000)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                64016     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 144,033\n",
      "Trainable params: 144,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 4s 225us/step - loss: 0.7537 - acc: 0.5010 - val_loss: 0.6944 - val_acc: 0.4938\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 4s 197us/step - loss: 0.6934 - acc: 0.4966 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 4s 200us/step - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6933 - val_acc: 0.4938\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 4s 192us/step - loss: 0.6932 - acc: 0.4978 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 4s 192us/step - loss: 0.6932 - acc: 0.4990 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 4s 209us/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 4s 202us/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 4s 198us/step - loss: 0.6932 - acc: 0.5016 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 4s 199us/step - loss: 0.6932 - acc: 0.4936 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 10/20\n",
      "20000/20000 [==============================] - 4s 204us/step - loss: 0.6932 - acc: 0.4963 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 11/20\n",
      "20000/20000 [==============================] - 4s 200us/step - loss: 0.6932 - acc: 0.4985 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 12/20\n",
      "20000/20000 [==============================] - 4s 199us/step - loss: 0.6932 - acc: 0.5009 - val_loss: 0.6933 - val_acc: 0.4938\n",
      "Epoch 13/20\n",
      "20000/20000 [==============================] - 4s 203us/step - loss: 0.6932 - acc: 0.4976 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 14/20\n",
      "20000/20000 [==============================] - 4s 196us/step - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 15/20\n",
      "20000/20000 [==============================] - 4s 193us/step - loss: 0.6932 - acc: 0.5013 - val_loss: 0.6931 - val_acc: 0.5062\n",
      "Epoch 16/20\n",
      "20000/20000 [==============================] - 4s 193us/step - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 17/20\n",
      "20000/20000 [==============================] - 4s 193us/step - loss: 0.6932 - acc: 0.4997 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 18/20\n",
      "20000/20000 [==============================] - 4s 193us/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6934 - val_acc: 0.4938\n",
      "Epoch 19/20\n",
      "20000/20000 [==============================] - 4s 193us/step - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.4938\n",
      "Epoch 20/20\n",
      "20000/20000 [==============================] - 4s 194us/step - loss: 0.6932 - acc: 0.4974 - val_loss: 0.6932 - val_acc: 0.4938\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim = max_features, output_dim=8, input_length=max_len))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.1)))\n",
    "\n",
    "model3.add(Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model3.summary()\n",
    "\n",
    "history3 = model3.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN(Recurrent Neural Network)\n",
    "- DNN, CNN과 다르게 메모리를 가짐, 그래서 sequence를 고려\n",
    "- 순환신경망(RNN) 은 처리한 정보를 각state에 저장\n",
    "- \n",
    "\n",
    "\n",
    "```{python}\n",
    "state_t=0\n",
    "for input_t in input_sequence:\n",
    "    output_t = activation(dot(W,input_t) + dot(U,state_t) + b)\n",
    "    state_t = ouput_t\n",
    "```  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 322,113\n",
      "Trainable params: 322,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN,Dense\n",
    "\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(input_dim = max_features,output_dim=32))\n",
    "rnn_model.add(SimpleRNN(32))\n",
    "rnn_model.add(Dense(1,activation='sigmoid'))\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7190035918692944694]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU tensorflow있나 보기\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.6110 - acc: 0.6565 - val_loss: 0.4619 - val_acc: 0.8152\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3921 - acc: 0.8367 - val_loss: 0.4164 - val_acc: 0.8164\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3027 - acc: 0.8831 - val_loss: 0.3862 - val_acc: 0.8310\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.2091 - acc: 0.9230 - val_loss: 0.3950 - val_acc: 0.8538\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.1489 - acc: 0.9474 - val_loss: 0.4118 - val_acc: 0.8572\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 27s 1ms/step - loss: 0.0935 - acc: 0.9696 - val_loss: 0.4750 - val_acc: 0.8140\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0568 - acc: 0.9826 - val_loss: 0.5477 - val_acc: 0.8252\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0373 - acc: 0.9893 - val_loss: 0.5539 - val_acc: 0.8298\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0199 - acc: 0.9949 - val_loss: 0.6171 - val_acc: 0.8048\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0167 - acc: 0.9953 - val_loss: 0.6155 - val_acc: 0.8356\n"
     ]
    }
   ],
   "source": [
    "# GPU 가 늘 빠르진 않다. RNN같은 계산은 CPU가 나을때도 있다.\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "    rnn_model.add(SimpleRNN(32))\n",
    "    rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    rnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = rnn_model.fit(X_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## L2 regularizer, dropout 적용\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, Dropout\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    rnn_model = Sequential()\n",
    "    rnn_model.add(Embedding(input_dim = max_features, output_dim=32))\n",
    "    rnn_model.add(SimpleRNN(32, kernel_regularizer=regularizers.l2(0.1)))\n",
    "    rnn_model.add(Dropout(0.5))\n",
    "    rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    rnn_model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    history = rnn_model.fit(X_train, y_train,\n",
    "                        epochs=10,\n",
    "                        batch_size=128,\n",
    "                        validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM(Long Short Term Memory)\n",
    "-RNN에 각각의 모델마다 sequence를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.4860 - acc: 0.7577 - val_loss: 0.3516 - val_acc: 0.8534\n",
      "Epoch 2/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.2485 - acc: 0.9050 - val_loss: 0.3014 - val_acc: 0.8726\n",
      "Epoch 3/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.1854 - acc: 0.9348 - val_loss: 0.3145 - val_acc: 0.8854\n",
      "Epoch 4/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.2339 - acc: 0.9083 - val_loss: 0.3317 - val_acc: 0.8706\n",
      "Epoch 5/10\n",
      "20000/20000 [==============================] - 76s 4ms/step - loss: 0.1317 - acc: 0.9560 - val_loss: 0.3659 - val_acc: 0.8754\n",
      "Epoch 6/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.0973 - acc: 0.9698 - val_loss: 0.3690 - val_acc: 0.8658\n",
      "Epoch 7/10\n",
      "20000/20000 [==============================] - 80s 4ms/step - loss: 0.0894 - acc: 0.9728 - val_loss: 0.4344 - val_acc: 0.8560\n",
      "Epoch 8/10\n",
      "20000/20000 [==============================] - 77s 4ms/step - loss: 0.0713 - acc: 0.9793 - val_loss: 0.4313 - val_acc: 0.8642\n",
      "Epoch 9/10\n",
      "20000/20000 [==============================] - 79s 4ms/step - loss: 0.0947 - acc: 0.9676 - val_loss: 0.4268 - val_acc: 0.8646\n",
      "Epoch 10/10\n",
      "20000/20000 [==============================] - 78s 4ms/step - loss: 0.0567 - acc: 0.9833 - val_loss: 0.4763 - val_acc: 0.8680\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,32))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n",
    "history = model.fit(X_train,y_train,epochs=10, batch_size = 128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# callback : EarlyStopping & ModelCheckpoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(monitor ='val_acc', patience=3),\n",
    "    \n",
    "    keras.callbacks.ModelCheckpoint(filepath='imdb_lstm.h5', monitor = 'val_loss', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "20000/20000 [==============================] - 49s 2ms/step - loss: 0.5596 - acc: 0.7312 - val_loss: 0.5358 - val_acc: 0.7412\n",
      "Epoch 2/20\n",
      "20000/20000 [==============================] - 50s 3ms/step - loss: 0.3308 - acc: 0.8794 - val_loss: 0.3268 - val_acc: 0.8712\n",
      "Epoch 3/20\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.2457 - acc: 0.9107 - val_loss: 0.3166 - val_acc: 0.8750\n",
      "Epoch 4/20\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1981 - acc: 0.9298 - val_loss: 0.3176 - val_acc: 0.8708\n",
      "Epoch 5/20\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1745 - acc: 0.9381 - val_loss: 0.2934 - val_acc: 0.8880\n",
      "Epoch 6/20\n",
      "20000/20000 [==============================] - 45s 2ms/step - loss: 0.1512 - acc: 0.9483 - val_loss: 0.3105 - val_acc: 0.8898\n",
      "Epoch 7/20\n",
      "20000/20000 [==============================] - 46s 2ms/step - loss: 0.1348 - acc: 0.9541 - val_loss: 0.3177 - val_acc: 0.8882\n",
      "Epoch 8/20\n",
      "20000/20000 [==============================] - 45s 2ms/step - loss: 0.1162 - acc: 0.9609 - val_loss: 0.3421 - val_acc: 0.8636\n",
      "Epoch 9/20\n",
      "20000/20000 [==============================] - 45s 2ms/step - loss: 0.1052 - acc: 0.9650 - val_loss: 0.3406 - val_acc: 0.8802\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,32))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train,y_train, epochs = 20, batch_size = 128, validation_split=0.2, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, None, 32)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 323,153\n",
      "Trainable params: 323,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
